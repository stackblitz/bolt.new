services:
  bolt-ai:
    image: bolt-ai:production
    build:
      context: .
      dockerfile: Dockerfile
      target: bolt-ai-production
    ports:
      - "5173:5173"
    env_file: ".env.local"
    environment:
      - NODE_ENV=production
      - COMPOSE_PROFILES=production
      # No strictly neded but serving as hints for Coolify
      - PORT=5173
      - GROQ_API_KEY=${GROQ_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPEN_ROUTER_API_KEY=${OPEN_ROUTER_API_KEY}
      - GOOGLE_GENERATIVE_AI_API_KEY=${GOOGLE_GENERATIVE_AI_API_KEY}
      - OLLAMA_API_BASE_URL=${OLLAMA_API_BASE_URL}
      - VITE_LOG_LEVEL=${VITE_LOG_LEVEL:-debug}
      - RUNNING_IN_DOCKER=true
    extra_hosts:
      - "host.docker.internal:host-gateway"      
    command: pnpm run dockerstart
    profiles:
      - production  # This service only runs in the production profile

  bolt-ai-dev:
    image: bolt-ai:development
    build:
      target: bolt-ai-development
    environment:
      - NODE_ENV=development
      - VITE_HMR_PROTOCOL=ws
      - VITE_HMR_HOST=localhost
      - VITE_HMR_PORT=5173
      - CHOKIDAR_USEPOLLING=true
      - WATCHPACK_POLLING=true  
      - PORT=5173
      - GROQ_API_KEY=${GROQ_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPEN_ROUTER_API_KEY=${OPEN_ROUTER_API_KEY}
      - GOOGLE_GENERATIVE_AI_API_KEY=${GOOGLE_GENERATIVE_AI_API_KEY}
      - OLLAMA_API_BASE_URL=${OLLAMA_API_BASE_URL}
      - VITE_LOG_LEVEL=${VITE_LOG_LEVEL:-debug}
      - RUNNING_IN_DOCKER=true
    extra_hosts:
      - "host.docker.internal:host-gateway"      
    volumes:
      - type: bind
        source: .
        target: /app
        consistency: cached
      - /app/node_modules
    ports:
      - "5173:5173"  # Same port, no conflict as only one runs at a time
    command: pnpm run dev --host 0.0.0.0
    profiles: ["development", "default"]  # Make development the default profile
